{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and preprocess the dataset\n",
    "\n",
    "First, let's load the dataset and preprocess it by removing stop words, punctuation, and other unwanted characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fresh</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fresh</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rotten</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rotten</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rotten</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Freshness                                             Review\n",
       "0     fresh   Manakamana doesn't answer any questions, yet ...\n",
       "1     fresh   Wilfully offensive and powered by a chest-thu...\n",
       "2    rotten   It would be difficult to imagine material mor...\n",
       "3    rotten   Despite the gusto its star brings to the role...\n",
       "4    rotten   If there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch and load the dataset\n",
    "dataFrame = pd.read_csv('rt_reviews.csv', encoding='ISO-8859-1')\n",
    "#view the dataset\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted characters\n",
    "dataFrame[\"Review\"] = dataFrame[\"Review\"].apply(lambda x: re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "stop_words = [\"a\", \"an\", \"the\", \"and\", \"or\", \"but\", \"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"being\", \"been\", \"have\", \"has\", \"had\", \"do\", \"does\", \"did\", \"will\", \"would\", \"shall\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\"]\n",
    "dataFrame[\"Review\"] = dataFrame[\"Review\"].apply(lambda x: \" \".join([word for word in x.split() if word.lower() not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "dataFrame[\"Review\"] = dataFrame[\"Review\"].apply(lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Divide the dataset into train, development, and test sets\n",
    "Next, let's divide the preprocessed dataset into train, development, and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "dataFrame = dataFrame.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into train, development, and test sets\n",
    "train_size = int(0.6 * len(dataFrame))\n",
    "dev_size = int(0.2 * len(dataFrame))\n",
    "test_size = len(dataFrame) - train_size - dev_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 288000\n",
      "Development size: 96000\n",
      "Test size: 96000\n"
     ]
    }
   ],
   "source": [
    "train_df = dataFrame[:train_size]\n",
    "dev_df = dataFrame[train_size:train_size+dev_size]\n",
    "test_df = dataFrame[train_size+dev_size:]\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Development size:\", len(dev_df))\n",
    "print(\"Test size:\", len(test_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build a vocabulary and reverse index\n",
    "Now, let's build a vocabulary and a reverse index using the train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 41167\n"
     ]
    }
   ],
   "source": [
    "# Build the vocabulary\n",
    "word_counts = {}\n",
    "for review in train_df[\"Review\"]:\n",
    "    for word in review.split():\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "vocab = [word for word, count in word_counts.items() if count >= 5]\n",
    "\n",
    "# Build the reverse index\n",
    "word2index = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "# Print the size of the vocabulary\n",
    "print(\"Vocabulary size:\", len(vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate probabilities\n",
    "\n",
    "Now, let's calculate the probabilities using the train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the prior probabilities\n",
    "num_fresh = sum(train_df[\"Freshness\"] == \"fresh\")\n",
    "num_rotten = sum(train_df[\"Freshness\"] == \"rotten\")\n",
    "total = len(train_df)\n",
    "\n",
    "prior_fresh = num_fresh / total\n",
    "prior_rotten = num_rotten / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the conditional probabilities\n",
    "word_counts_fresh = np.zeros(len(vocab))\n",
    "word_counts_rotten = np.zeros(len(vocab))\n",
    "\n",
    "for review, freshness in zip(train_df[\"Review\"], train_df[\"Freshness\"]):\n",
    "    for word in review.split():\n",
    "        if word in word2index:\n",
    "            i = word2index[word]\n",
    "            if freshness == \"fresh\":\n",
    "                word_counts_fresh[i] += 1\n",
    "            else:\n",
    "                word_counts_rotten[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add smoothing to the word counts\n",
    "alpha = 1\n",
    "word_probs_fresh = (word_counts_fresh + alpha) / (num_fresh + alpha * len(vocab))\n",
    "word_probs_rotten = (word_counts_rotten + alpha) / (num_rotten + alpha * len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities without smoothing\n",
    "word_probs_fresh_no_smooth = word_counts_fresh / num_fresh\n",
    "word_probs_rotten_no_smooth = word_counts_rotten / num_rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Guardians:\n",
      "\tP(word|fresh): 0.000475359625762331\n",
      "\tP(word|rotten): 0.00016197742034760354\n",
      "\n",
      "of:\n",
      "\tP(word|fresh): 0.5311117473247516\n",
      "\tP(word|rotten): 0.46476721145072375\n",
      "\n",
      "Galaxy:\n",
      "\tP(word|fresh): 0.00034031427753439605\n",
      "\tP(word|rotten): 9.718645220856213e-05\n",
      "\n",
      "firstclass:\n",
      "\tP(word|fresh): 0.0001890634875191089\n",
      "\tP(word|rotten): 4.3193978759360944e-05\n",
      "\n",
      "GradeA:\n",
      "\tP(word|fresh): 3.2410883574704386e-05\n",
      "\tP(word|rotten): 1.6197742034760356e-05\n",
      "\n",
      "space:\n",
      "\tP(word|fresh): 0.002198538269150781\n",
      "\tP(word|rotten): 0.00183034484992792\n",
      "\n",
      "adventure:\n",
      "\tP(word|fresh): 0.00591498625238355\n",
      "\tP(word|rotten): 0.00274821689856434\n",
      "\n",
      "comedy:\n",
      "\tP(word|fresh): 0.023443872452369504\n",
      "\tP(word|rotten): 0.02603517069720481\n",
      "\n",
      "For:\n",
      "\tP(word|fresh): 0.008253971683691384\n",
      "\tP(word|rotten): 0.00917332123901928\n",
      "\n",
      "while:\n",
      "\tP(word|fresh): 0.01426078877286993\n",
      "\tP(word|rotten): 0.011581385554853654\n"
     ]
    }
   ],
   "source": [
    "# Print the probabilities of the first 10 words in the vocabulary\n",
    "for i in range(10):\n",
    "    word = vocab[i]\n",
    "    print(\"\\n\"+word+':')\n",
    "    print(\"\\tP(word|fresh):\", word_probs_fresh[i])\n",
    "    print(\"\\tP(word|rotten):\", word_probs_rotten[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Calculate accuracy on development set\n",
    "\n",
    "Next, let's calculate the accuracy on the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to naive bayes classify a review\n",
    "def classify(review, smoothing=True):\n",
    "    if smoothing:\n",
    "        fresh_prob = prior_fresh + len(word_counts_fresh)\n",
    "        rotten_prob = prior_rotten + len(word_counts_rotten)\n",
    "    else:\n",
    "        fresh_prob = prior_fresh\n",
    "        rotten_prob = prior_rotten\n",
    "    \n",
    "    for word in review.split():\n",
    "        if word in word2index:\n",
    "            i = word2index[word]\n",
    "            if smoothing:\n",
    "                fresh_prob *= (word_counts_fresh[i] + 1) / (num_fresh + len(word_counts_fresh))\n",
    "                rotten_prob *= (word_counts_rotten[i] + 1) / (num_rotten + len(word_counts_rotten))\n",
    "            else:\n",
    "                fresh_prob *= word_probs_fresh[i]\n",
    "                rotten_prob *= word_probs_rotten[i]\n",
    "    \n",
    "    if fresh_prob > rotten_prob:\n",
    "        return \"fresh\"\n",
    "    else:\n",
    "        return \"rotten\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development accuracy: 0.7963854166666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91837\\AppData\\Local\\Temp\\ipykernel_21588\\1509339959.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_df.loc[:,\"Prediction\"] = dev_df[\"Review\"].apply(classify)\n"
     ]
    }
   ],
   "source": [
    "# Classify the reviews in the development set\n",
    "dev_df.loc[:,\"Prediction\"] = dev_df[\"Review\"].apply(classify)\n",
    "\n",
    "# Calculate the accuracy on the development set\n",
    "dev_accuracy = sum(dev_df[\"Prediction\"] == dev_df[\"Freshness\"]) / len(dev_df)\n",
    "print(\"Development accuracy:\", dev_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6a: Compare the effect of smoothing\n",
    "\n",
    "Now, let's compare the effect of smoothing by calculating the accuracies with and without smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development accuracy without smoothing: 0.796375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91837\\AppData\\Local\\Temp\\ipykernel_21588\\4128684334.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_df.loc[:, \"Prediction_no_smooth\"] = dev_df[\"Review\"].apply(lambda x: classify(x, False))\n"
     ]
    }
   ],
   "source": [
    "# Classify the reviews in the development set without smoothing\n",
    "dev_df.loc[:, \"Prediction_no_smooth\"] = dev_df[\"Review\"].apply(lambda x: classify(x, False))\n",
    "\n",
    "# Calculate the accuracy on the development set without smoothing\n",
    "dev_accuracy_no_smooth = sum(dev_df[\"Prediction_no_smooth\"] == dev_df[\"Freshness\"]) / len(dev_df)\n",
    "print(\"Development accuracy without smoothing:\", dev_accuracy_no_smooth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6b: Derive top 10 words that predict each class\n",
    "\n",
    "Next, let's derive the top 10 words that predict each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words that predict fresh: ['unadorned', 'SpiderVerse', 'Holofcener', 'unmissable', 'restores', 'Brilliantly', 'Impressively', 'razorsharp', 'Fallout', 'Gripping']\n",
      "Top 10 words that predict rotten: ['thirdrate', 'Tedious', 'Battlefield', 'cheaplooking', 'unexciting', 'laziest', 'flavorless', 'unfunny', 'feeble', 'charmless']\n"
     ]
    }
   ],
   "source": [
    "# Derive the top 10 words that predict freshness\n",
    "fresh_probs = word_probs_fresh / word_probs_rotten\n",
    "fresh_top_10 = [vocab[i] for i in np.argsort(fresh_probs)[-10:]]\n",
    "print(\"Top 10 words that predict fresh:\", fresh_top_10)\n",
    "\n",
    "# Derive the top 10 words that predict rotten\n",
    "rotten_probs = word_probs_rotten / word_probs_fresh\n",
    "rotten_top_10 = [vocab[i] for i in np.argsort(rotten_probs)[-10:]]\n",
    "print(\"Top 10 words that predict rotten:\", rotten_top_10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6c: P[class | word]\n",
    "\n",
    "Finally, let's calculate P[class | word] for a given word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fresh': 0.5192850636876635, 'rotten': 0.4807149363123365}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to calculate P[class | word]\n",
    "def p_class_given_word(word):\n",
    "    if word in word2index:\n",
    "        i = word2index[word]\n",
    "        p_word_fresh = word_probs_fresh[i]\n",
    "        p_word_rotten = word_probs_rotten[i]\n",
    "        p_fresh_word = p_rotten_word = word_probs_rotten[i]\n",
    "        return {\"fresh\": p_word_fresh / (p_word_fresh + p_word_rotten), \n",
    "                \"rotten\": p_word_rotten / (p_word_fresh + p_word_rotten)}\n",
    "    else:\n",
    "        return {\"fresh\": 0, \"rotten\": 0}\n",
    "\n",
    "# Calculate P[class | word] for the word \"good\"\n",
    "p_class_given_word(\"good\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Calculate final accuracy on test set\n",
    "\n",
    "Finally, let's calculate the final accuracy on the test set using the optimal hyperparameters we found on the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.79928125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91837\\AppData\\Local\\Temp\\ipykernel_21588\\632861865.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.loc[:, \"Prediction\"] = test_df[\"Review\"].apply(classify)\n"
     ]
    }
   ],
   "source": [
    "# Classify the reviews in the test set\n",
    "test_df.loc[:, \"Prediction\"] = test_df[\"Review\"].apply(classify)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_accuracy = sum(test_df[\"Prediction\"] == test_df[\"Freshness\"]) / len(test_df)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
